{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "629e0239",
   "metadata": {},
   "source": [
    "\n",
    "**Question 10.**\n",
    "\n",
    "Write a program to count the number of verbs, nouns, pronouns, and adjectives in a given particular phrase or\n",
    "paragraph, and return their respective count as a dictionary.\n",
    "Note -\n",
    "1. Write code comments wherever required for code\n",
    "2. You have to write at least 2 additional test cases in which your program will run successfully and provide\n",
    "an explanation for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d450fc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import nltk \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83df7dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "txt = \"The first-flight failure of Starship \"\\\n",
    "\"One was a very high-profile casualty in the 21st Century's new \"\\\n",
    "\"race for space. SpaceX said its failure provided many key lessons\"\\\n",
    "\"for the next launch, which will only take place after weeks of\"\\\n",
    "\"clean-up at the badly damaged Boca Chica site.\"\\\n",
    "\"SpaceX don't consider it a failure, but a springboard \"\\\n",
    "\"to solving issues before the next launch.\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "txt = \"He compares the Proton's success rate to the European Ariane 4 and the American Delta II\"\\\n",
    "\"rocket, both of which chalked up more than 100 successful launches in a row. \"\\\n",
    "\"What you used to see with Proton was… there'd be a failure every 20 to 25 flights. I think in Russia,\"\\\n",
    "\"in the 1960s, you saw a lot of people come into the industry because of the space race.\"\\\n",
    "\"These were the best and brightest people straight out of university, the absolute best graduates\"\n",
    "\n",
    "\n",
    "\n",
    "txt = \"It's impossible to say if Hubble – and its vast scientific\"\\\n",
    "\"achievements – would have existed without the Apollo Moon landing programme.\"\\\n",
    "\"Apollo certainly revolutionised and accelerated space technology along with our\"\\\n",
    "\"ability to live and work in space. But, perhaps more significantly, Massimino is\"\\\n",
    "\"among a generation of children who – thanks to watching astronauts walk on the Moon –\"\\\n",
    "\"were inspired to become scientists, engineers or astronomers.\"\\\n",
    "\"People who have helped develop new cancer treatments, designed the smartphone and built Hubble.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0d84096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'impossible',\n",
       " 'to',\n",
       " 'say',\n",
       " 'if',\n",
       " 'Hubble',\n",
       " '–',\n",
       " 'and',\n",
       " 'its',\n",
       " 'vast',\n",
       " 'scientificachievements',\n",
       " '–',\n",
       " 'would',\n",
       " 'have',\n",
       " 'existed',\n",
       " 'without',\n",
       " 'the',\n",
       " 'Apollo',\n",
       " 'Moon',\n",
       " 'landing',\n",
       " 'programme.Apollo',\n",
       " 'certainly',\n",
       " 'revolutionised',\n",
       " 'and',\n",
       " 'accelerated',\n",
       " 'space',\n",
       " 'technology',\n",
       " 'along',\n",
       " 'with',\n",
       " 'ourability',\n",
       " 'to',\n",
       " 'live',\n",
       " 'and',\n",
       " 'work',\n",
       " 'in',\n",
       " 'space',\n",
       " '.',\n",
       " 'But',\n",
       " ',',\n",
       " 'perhaps',\n",
       " 'more',\n",
       " 'significantly',\n",
       " ',',\n",
       " 'Massimino',\n",
       " 'isamong',\n",
       " 'a',\n",
       " 'generation',\n",
       " 'of',\n",
       " 'children',\n",
       " 'who',\n",
       " '–',\n",
       " 'thanks',\n",
       " 'to',\n",
       " 'watching',\n",
       " 'astronauts',\n",
       " 'walk',\n",
       " 'on',\n",
       " 'the',\n",
       " 'Moon',\n",
       " '–were',\n",
       " 'inspired',\n",
       " 'to',\n",
       " 'become',\n",
       " 'scientists',\n",
       " ',',\n",
       " 'engineers',\n",
       " 'or',\n",
       " 'astronomers.People',\n",
       " 'who',\n",
       " 'have',\n",
       " 'helped',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'cancer',\n",
       " 'treatments',\n",
       " ',',\n",
       " 'designed',\n",
       " 'the',\n",
       " 'smartphone',\n",
       " 'and',\n",
       " 'built',\n",
       " 'Hubble',\n",
       " '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_list = word_tokenize(txt)  \n",
    "words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b6376d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_list = [w for w in words_list if w not in stopwords]      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46aacbd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'impossible',\n",
       " 'say',\n",
       " 'Hubble',\n",
       " '–',\n",
       " 'vast',\n",
       " 'scientificachievements',\n",
       " '–',\n",
       " 'would',\n",
       " 'existed',\n",
       " 'without',\n",
       " 'Apollo',\n",
       " 'Moon',\n",
       " 'landing',\n",
       " 'programme.Apollo',\n",
       " 'certainly',\n",
       " 'revolutionised',\n",
       " 'accelerated',\n",
       " 'space',\n",
       " 'technology',\n",
       " 'along',\n",
       " 'ourability',\n",
       " 'live',\n",
       " 'work',\n",
       " 'space',\n",
       " '.',\n",
       " 'But',\n",
       " ',',\n",
       " 'perhaps',\n",
       " 'significantly',\n",
       " ',',\n",
       " 'Massimino',\n",
       " 'isamong',\n",
       " 'generation',\n",
       " 'children',\n",
       " '–',\n",
       " 'thanks',\n",
       " 'watching',\n",
       " 'astronauts',\n",
       " 'walk',\n",
       " 'Moon',\n",
       " '–were',\n",
       " 'inspired',\n",
       " 'become',\n",
       " 'scientists',\n",
       " ',',\n",
       " 'engineers',\n",
       " 'astronomers.People',\n",
       " 'helped',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'cancer',\n",
       " 'treatments',\n",
       " ',',\n",
       " 'designed',\n",
       " 'smartphone',\n",
       " 'built',\n",
       " 'Hubble',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1da1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfb64253",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_list = [i for i in clean_list if not i in punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76d5c78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['It',\n",
       " \"'s\",\n",
       " 'impossible',\n",
       " 'say',\n",
       " 'Hubble',\n",
       " '–',\n",
       " 'vast',\n",
       " 'scientificachievements',\n",
       " '–',\n",
       " 'would',\n",
       " 'existed',\n",
       " 'without',\n",
       " 'Apollo',\n",
       " 'Moon',\n",
       " 'landing',\n",
       " 'programme.Apollo',\n",
       " 'certainly',\n",
       " 'revolutionised',\n",
       " 'accelerated',\n",
       " 'space',\n",
       " 'technology',\n",
       " 'along',\n",
       " 'ourability',\n",
       " 'live',\n",
       " 'work',\n",
       " 'space',\n",
       " 'But',\n",
       " 'perhaps',\n",
       " 'significantly',\n",
       " 'Massimino',\n",
       " 'isamong',\n",
       " 'generation',\n",
       " 'children',\n",
       " '–',\n",
       " 'thanks',\n",
       " 'watching',\n",
       " 'astronauts',\n",
       " 'walk',\n",
       " 'Moon',\n",
       " '–were',\n",
       " 'inspired',\n",
       " 'become',\n",
       " 'scientists',\n",
       " 'engineers',\n",
       " 'astronomers.People',\n",
       " 'helped',\n",
       " 'develop',\n",
       " 'new',\n",
       " 'cancer',\n",
       " 'treatments',\n",
       " 'designed',\n",
       " 'smartphone',\n",
       " 'built',\n",
       " 'Hubble']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a00f0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_words = nltk.pos_tag(clean_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c16ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/chinmay/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> import nltk\n",
    ">>> nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41b9abff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('It', 'PRP'),\n",
       " (\"'s\", 'VBZ'),\n",
       " ('impossible', 'JJ'),\n",
       " ('say', 'VBP'),\n",
       " ('Hubble', 'JJ'),\n",
       " ('–', 'JJ'),\n",
       " ('vast', 'JJ'),\n",
       " ('scientificachievements', 'NNS'),\n",
       " ('–', 'WDT'),\n",
       " ('would', 'MD'),\n",
       " ('existed', 'VB'),\n",
       " ('without', 'IN'),\n",
       " ('Apollo', 'NNP'),\n",
       " ('Moon', 'NNP'),\n",
       " ('landing', 'VBG'),\n",
       " ('programme.Apollo', 'NN'),\n",
       " ('certainly', 'RB'),\n",
       " ('revolutionised', 'VBD'),\n",
       " ('accelerated', 'JJ'),\n",
       " ('space', 'NN'),\n",
       " ('technology', 'NN'),\n",
       " ('along', 'IN'),\n",
       " ('ourability', 'NN'),\n",
       " ('live', 'JJ'),\n",
       " ('work', 'NN'),\n",
       " ('space', 'NN'),\n",
       " ('But', 'CC'),\n",
       " ('perhaps', 'RB'),\n",
       " ('significantly', 'RB'),\n",
       " ('Massimino', 'NNP'),\n",
       " ('isamong', 'JJ'),\n",
       " ('generation', 'NN'),\n",
       " ('children', 'NNS'),\n",
       " ('–', 'VBP'),\n",
       " ('thanks', 'NNS'),\n",
       " ('watching', 'VBG'),\n",
       " ('astronauts', 'NNS'),\n",
       " ('walk', 'VBP'),\n",
       " ('Moon', 'NNP'),\n",
       " ('–were', 'RB'),\n",
       " ('inspired', 'VBD'),\n",
       " ('become', 'JJ'),\n",
       " ('scientists', 'NNS'),\n",
       " ('engineers', 'NNS'),\n",
       " ('astronomers.People', 'VBP'),\n",
       " ('helped', 'VBD'),\n",
       " ('develop', 'VB'),\n",
       " ('new', 'JJ'),\n",
       " ('cancer', 'NN'),\n",
       " ('treatments', 'NNS'),\n",
       " ('designed', 'VBN'),\n",
       " ('smartphone', 'NN'),\n",
       " ('built', 'VBN'),\n",
       " ('Hubble', 'JJ')]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92562600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noun : 20, Pronoun : 1, Adjective : 10, Verb :14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'nouns': 20, 'pronouns': 1, 'verbs': 14, 'adjectives': 10}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_n = 0 \n",
    "count_verb = 0 \n",
    "count_prn = 0\n",
    "count_adj = 0\n",
    "\n",
    "for i in tagged_words: \n",
    "    if i[1] == 'NN' or i[1] == 'NNS' or i[1] == 'NNP'or i[1] == 'NNPS': \n",
    "        count_n = count_n + 1\n",
    "        \n",
    "    elif i[1] == 'PRP' or i[1] == 'PRP$' or i[1] == 'WP'or i[1] == 'WP$'or i[1] == 'WRB': \n",
    "        count_prn = count_prn + 1    \n",
    "        \n",
    "    elif i[1] == 'JJ' or i[1] == 'JJR' or i[1] == 'JJS': \n",
    "        count_adj = count_adj + 1     \n",
    "        \n",
    "    elif i[1] == 'VB' or i[1] == 'VBD' or i[1] == 'VBG'or i[1] == 'VBN'or i[1] == 'VBP' or i[1] == 'VBZ': \n",
    "        count_verb = count_verb + 1     \n",
    "        \n",
    "        \n",
    "print(f'Noun : {count_n}, Pronoun : {count_prn}, Adjective : {count_adj}, Verb :{count_verb}')\n",
    "\n",
    "mydic = dict()\n",
    "\n",
    "mydic[\"nouns\"] = count_n\n",
    "mydic[\"pronouns\"] = count_prn \n",
    "mydic[\"verbs\"] = count_verb\n",
    "mydic['adjectives'] = count_adj\n",
    "\n",
    "mydic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bafada76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_dict(intext): \n",
    "    \"\"\"\n",
    "    This function will take text data as input and return the number of nouns, pronouns, \n",
    "    adjective and verbs in dictionary format.    \n",
    "    \"\"\"\n",
    "    \n",
    "    # cleaning the text data \n",
    "    \n",
    "    token_words = word_tokenize(intext)\n",
    "    clean_words = [w for w in token_words if not w in stopwords] \n",
    "    clean_words = [w for w in clean_words if not w in punctuation]\n",
    "    \n",
    "    pos_tagged_words = nltk.pos_tag(clean_words)\n",
    "    \n",
    "    \n",
    "    # counting the number of nounsm pronouns adjective and verbs\n",
    "    \n",
    "    n_n = 0 \n",
    "    n_verb = 0 \n",
    "    n_prn = 0\n",
    "    n_adj = 0\n",
    "\n",
    "    for i in pos_tagged_words: \n",
    "        if i[1] == 'NN' or i[1] == 'NNS' or i[1] == 'NNP' or i[1] == 'NNPS': \n",
    "            n_n = n_n + 1\n",
    "        \n",
    "        elif i[1] == 'PRP' or i[1] == 'PRP$' or i[1] == 'WP' or i[1] == 'WP$' or i[1] == 'WRB': \n",
    "            n_prn = n_prn + 1    \n",
    "        \n",
    "        elif i[1] == 'JJ' or i[1] == 'JJR' or i[1] == 'JJS': \n",
    "            n_adj = n_adj + 1     \n",
    "        \n",
    "        elif i[1] == 'VB' or i[1] == 'VBD' or i[1] == 'VBG'or i[1] == 'VBN' or i[1] == 'VBP' or i[1] == 'VBZ': \n",
    "            n_verb = n_verb + 1     \n",
    "        \n",
    "        \n",
    "    #print(f'Noun : {count_n}, Pronoun : {count_prn}, Adjective : {count_adj}, Verb :{count_verb}')\n",
    "\n",
    "    mydict = dict()\n",
    "\n",
    "    mydict[\"nouns\"] = n_n\n",
    "    mydict[\"pronouns\"] = n_prn \n",
    "    mydict[\"verbs\"] = n_verb\n",
    "    mydict['adjectives'] = n_adj\n",
    "    \n",
    "    return mydict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85f1ef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nouns': 20, 'pronouns': 1, 'verbs': 14, 'adjectives': 10}\n"
     ]
    }
   ],
   "source": [
    "#mytext = input()\n",
    "\n",
    "print(get_pos_dict(txt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6c7888",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5b10b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0c4ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3725afe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee82cbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e86edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e57e5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113aa066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
